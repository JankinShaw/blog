I"J<h1 id="lecture-10-模型创建步骤与-nnmodule">Lecture 10 模型创建步骤与 nn.Module</h1>

<p>前几节课中，我们学习了 PyTorch 的数据模块，并了解了 PyTorch 如何从硬盘中读取数据，然后对数据进行预处理、数据增强，最后转换为张量的形式输入到我们的模型中。在深度模型中，会对张量进行一系列复杂的数学运算，最终得到用于分类、分割、目标检测等任务的输入。本节课中，我们将学习 PyTorch 中模型的创建以及 <code class="language-plaintext highlighter-rouge">nn.Module</code> 的相关概念。</p>

<h2 id="1-网络模型的创建步骤">1. 网络模型的创建步骤</h2>

<p>在学习创建模型之前，我们先回顾一下之前提到的机器学习模型训练的 5 个步骤：</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-11-WX20201211-145639%402x.png" width="90%" /></p>

<p>我们已经在前几节课中完成了对数据模块的学习，接下来我们开始学习模型模块。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-13-WX20201213-152822%402x.png" width="90%" /></p>

<p>回顾一下之前在人民币分类的例子中我们使用过的 LeNet 网络：</p>

<p><strong>LeNet 模型结构图</strong>：</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-13-WX20201213-154400%402x.png" width="90%" /></p>

<p>可以看到，LeNet 网络由 7 个层构成：卷积层 1、池化层 1、卷积层 2、池化层 2，以及 3 个全连接层。在创建 LeNet 时，需要先构建这些子模块，在构建完成这 7 个子网络层后，我们会采用一定的顺序对其进行连接。最后，将它们包装起来就得到我们的 LeNet 网络。</p>

<p>在 PyTorch 中，LeNet 是一个 Module 的概念，而它的子网络层也是一个 Module 的概念，它们都属于 <code class="language-plaintext highlighter-rouge">nn.Module</code> 类。所以，一个 <code class="language-plaintext highlighter-rouge">nn.Module</code> (例如：LeNet) 可以包含很多个子 Module (例如：卷积层、池化层等)。</p>

<p>下面我们从计算图的角度来观察模型的创建过程：</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-13-WX20201213-162022%402x.png" /></p>

<p>计算图中有两个主要的概念：结点和边。其中，结点代表张量 (数据)，边代表运算。LeNet 整体上可以视为一组张量运算：它接收一个 $32\times 32\times 3$ 的张量，经过一系列复杂运算之后，输出一个长度为 $10$ 的向量作为分类概率。而在 LeNet 内部，则由一系列子网络层构成，例如：卷积层 1 对一个 $32\times 32\times 3$ 的张量进行卷积操作得到一个 $28\times 28\times 6$ 的张量，并将其作为下一层子网络的输入，经过这种不断的前向传播，最终计算得到输出概率。在深度学习中，该过程被称为 <strong>前向传播</strong>。</p>

<p>我们从网络结构和计算图的角度分析了 LeNet 网络模型，并且知道了构建模型的两个要素：构建子模块和拼接子模块。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-13-WX20201213-163431%402x.png" width="60%" /></p>

<p>接下来，我们还是通过之前人民币二分类的例子来学习如何构建模型。</p>

<p><strong>构建模型</strong>：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="c1"># ============================ step 2/5 模型 ============================
</span><span class="n">net</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">(</span><span class="n">classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">net</span><span class="p">.</span><span class="n">initialize_weights</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>LeNet 类</strong>：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre></td><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">LeNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># 构建子模块
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>

    <span class="c1"># 拼接子模块
</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">m</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
                <span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">):</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
                <span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="2-nnmodule">2. <code class="language-plaintext highlighter-rouge">nn.Module</code></h2>

<p>在模型模块中，我们有一个非常重要的概念 —— <code class="language-plaintext highlighter-rouge">nn.Module</code>。我们所有的模型和网络层都是继承自 <code class="language-plaintext highlighter-rouge">nn.Module</code> 这个类的，所以我们有必要了解它。在学习 <code class="language-plaintext highlighter-rouge">nn.Module</code> 之前，我们先来看一下与其相关的几个模块：</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-13-WX20201213-165842%402x.png" width="90%" /></p>

<p>首先是 <code class="language-plaintext highlighter-rouge">torch.nn</code>，它是 PyTorch 的一个神经网络模块，其中又有很多子模块，这里我们需要了解其中的 4 个模块：<code class="language-plaintext highlighter-rouge">nn.Parameter</code>、<code class="language-plaintext highlighter-rouge">nn.Module</code>、<code class="language-plaintext highlighter-rouge">nn.functional</code> 和 <code class="language-plaintext highlighter-rouge">nn.init</code>。本节课我们先重点关注 <code class="language-plaintext highlighter-rouge">nn.Module</code>。</p>

<h4 id="nnmodule"><code class="language-plaintext highlighter-rouge">nn.Module</code></h4>

<p>在 <code class="language-plaintext highlighter-rouge">nn.Module</code> 中有 8 个重要的属性，用于管理整个模型：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="bp">self</span><span class="p">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span class="bp">self</span><span class="p">.</span><span class="n">_buffers</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span class="bp">self</span><span class="p">.</span><span class="n">_backward_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span class="bp">self</span><span class="p">.</span><span class="n">_forward_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span class="bp">self</span><span class="p">.</span><span class="n">_forward_pre_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span class="bp">self</span><span class="p">.</span><span class="n">_state_dict_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span class="bp">self</span><span class="p">.</span><span class="n">_load_state_dict_pre_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span class="bp">self</span><span class="p">.</span><span class="n">_modules</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要属性</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">parameters</code>：存储管理 <code class="language-plaintext highlighter-rouge">nn.Parameter</code> 类。</li>
  <li><code class="language-plaintext highlighter-rouge">modules</code>：存储管理 <code class="language-plaintext highlighter-rouge">nn.Module</code> 类。</li>
  <li><code class="language-plaintext highlighter-rouge">buffers</code>：存储管理缓冲属性，如 BN 层中的 <code class="language-plaintext highlighter-rouge">running_mean</code>。</li>
  <li><code class="language-plaintext highlighter-rouge">***_hooks</code>：存储管理钩子函数。</li>
</ul>

<p>这里，我们重点关注其中的两个属性：<code class="language-plaintext highlighter-rouge">parameters</code> 和 <code class="language-plaintext highlighter-rouge">modules</code>。</p>

<p><strong><code class="language-plaintext highlighter-rouge">nn.Module</code> 的属性构建机制</strong>：</p>

<p>在 <code class="language-plaintext highlighter-rouge">module</code> 类里面进行属性赋值时会先被 <code class="language-plaintext highlighter-rouge">__setattr__</code> 函数拦截，该函数对即将赋值的数据类型进行判断：如果赋值是 <code class="language-plaintext highlighter-rouge">nn.Parameter</code> 类，则将其存入 <code class="language-plaintext highlighter-rouge">parameters</code> 字典中进行管理；如果赋值是 <code class="language-plaintext highlighter-rouge">nn.Module</code> 类，则将其存入 <code class="language-plaintext highlighter-rouge">modules</code> 字典中进行管理。</p>

<p><strong><code class="language-plaintext highlighter-rouge">nn.Module</code> 总结</strong>：</p>

<ul>
  <li>一个 module 可以包含多个子 module。
    <ul>
      <li>例如：在 LeNet 这个 module 下会包含一些卷积层、池化层等子 module。</li>
    </ul>
  </li>
  <li>一个 module 相当于一个运算，必须实现 <code class="language-plaintext highlighter-rouge">forward()</code> 函数。
    <ul>
      <li>从计算图的角度来看，一个 module 接收一个张量，经过一系列复杂运算，输出概率或者其他数据。因此，我们需要在其中实现一个前向传播的函数。</li>
    </ul>
  </li>
  <li>每个 module 都有 8 个 <strong>有序字典 (<code class="language-plaintext highlighter-rouge">OrderedDict</code>)</strong> 管理它的属性。
    <ul>
      <li>这里，最常用的是 <code class="language-plaintext highlighter-rouge">parameters</code> 字典和 <code class="language-plaintext highlighter-rouge">modules</code> 字典。</li>
    </ul>
  </li>
</ul>

<h2 id="3-总结">3. 总结</h2>

<p>本节课中，我们学习了 <code class="language-plaintext highlighter-rouge">nn.Module</code> 的概念以及模型创建的两个要素。下节课中，我们将学习容器 Containers 以及 AlexNet 的搭建。</p>

<p>下节内容：模型容器与 AlexNet 构建</p>
:ET