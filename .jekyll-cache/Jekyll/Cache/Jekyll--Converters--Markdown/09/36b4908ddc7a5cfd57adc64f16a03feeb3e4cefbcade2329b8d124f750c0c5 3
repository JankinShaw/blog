I"zz<h1 id="lecture-03-张量操作与线性回归">Lecture 03 张量操作与线性回归</h1>

<h2 id="1-张量操作">1. 张量操作</h2>
<h3 id="11-张量拼接与切分">1.1 张量拼接与切分</h3>

<h4 id="torchcat"><code class="language-plaintext highlighter-rouge">torch.cat()</code></h4>

<p><strong>功能</strong>：将张量按维度 <code class="language-plaintext highlighter-rouge">dim</code> 进行拼接。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span>
    <span class="n">tensors</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">out</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">tensors</code>：张量序列。</li>
  <li><code class="language-plaintext highlighter-rouge">dim</code>：要拼接的维度。</li>
</ul>

<h4 id="torchstack"><code class="language-plaintext highlighter-rouge">torch.stack()</code></h4>

<p><strong>功能</strong>：在 <strong>新创建的维度</strong> <code class="language-plaintext highlighter-rouge">dim</code> 上进行拼接。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span>
    <span class="n">tensors</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">out</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">tensors</code>：张量序列。</li>
  <li><code class="language-plaintext highlighter-rouge">dim</code>：要拼接的维度。</li>
</ul>

<h4 id="torchchunk"><code class="language-plaintext highlighter-rouge">torch.chunk()</code></h4>

<p><strong>功能</strong>：将张量按维度 <code class="language-plaintext highlighter-rouge">dim</code> 进行 <strong>平均切分</strong>。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">chunk</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">chunks</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">input</code>：要切分的张量。</li>
  <li><code class="language-plaintext highlighter-rouge">chunks</code>：要切分的份数。</li>
  <li><code class="language-plaintext highlighter-rouge">dim</code>：要切分的维度。</li>
</ul>

<p><strong>返回值</strong>：张量列表。</p>

<p><strong>注意事项</strong>：若不能整除，最后一份张量将小于其他张量。</p>

<h4 id="torchsplit"><code class="language-plaintext highlighter-rouge">torch.split()</code></h4>

<p><strong>功能</strong>：将张量按维度 <code class="language-plaintext highlighter-rouge">dim</code> 进行切分。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">split</span><span class="p">(</span>
    <span class="n">tensor</span><span class="p">,</span>
    <span class="n">split_size_or_sections</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">tensor</code>：要切分的张量。</li>
  <li><code class="language-plaintext highlighter-rouge">split_size_or_sections</code>：为 <code class="language-plaintext highlighter-rouge">int</code> 时，表示每一份的长度；为 <code class="language-plaintext highlighter-rouge">list</code> 时，按 <code class="language-plaintext highlighter-rouge">list</code> 元素切分。</li>
  <li><code class="language-plaintext highlighter-rouge">dim</code>：要切分的维度。</li>
</ul>

<p><strong>返回值</strong>：张量列表。</p>

<h3 id="12-张量索引">1.2 张量索引</h3>

<h4 id="torchindex_select"><code class="language-plaintext highlighter-rouge">torch.index_select()</code></h4>

<p><strong>功能</strong>：在维度 <code class="language-plaintext highlighter-rouge">dim</code> 上，按 <code class="language-plaintext highlighter-rouge">index</code> 索引数据。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">index_select</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">,</span>
    <span class="n">index</span><span class="p">,</span>
    <span class="n">out</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">input</code>：要索引的张量。</li>
  <li><code class="language-plaintext highlighter-rouge">dim</code>：要索引的维度。</li>
  <li><code class="language-plaintext highlighter-rouge">index</code>：要索引数据的序号，注意这里 <code class="language-plaintext highlighter-rouge">index</code> 中的数据类型必须是 <code class="language-plaintext highlighter-rouge">torch.long</code>。</li>
</ul>

<p><strong>返回值</strong>：依 <code class="language-plaintext highlighter-rouge">index</code> 索引数据拼接的张量。</p>

<h4 id="torchmasked_select"><code class="language-plaintext highlighter-rouge">torch.masked_select()</code></h4>

<p><strong>功能</strong>：按 <code class="language-plaintext highlighter-rouge">mask</code> 中的 <code class="language-plaintext highlighter-rouge">True</code> 进行索引。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">masked_select</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">mask</span><span class="p">,</span>
    <span class="n">out</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">input</code>：要索引的张量。</li>
  <li><code class="language-plaintext highlighter-rouge">mask</code>：与 <code class="language-plaintext highlighter-rouge">input</code> 同形状的布尔类型张量。</li>
</ul>

<p><strong>返回值</strong>：<strong>一维</strong> 张量。</p>

<h3 id="13-张量变换">1.3 张量变换</h3>

<h4 id="torchreshape"><code class="language-plaintext highlighter-rouge">torch.reshape()</code></h4>

<p><strong>功能</strong>：变换张量形状。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">shape</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">input</code>：要变换的张量。</li>
  <li><code class="language-plaintext highlighter-rouge">shape</code>：新张量的形状，当我们不需要关心某个维度时，可以将其设为 -1，它将通过对其他维度的计算自动得出。</li>
</ul>

<p><strong>注意事项</strong>：当张量在内存中是连续时，新张量与 <code class="language-plaintext highlighter-rouge">input</code> 共享数据内存。</p>

<h4 id="torchtranspose"><code class="language-plaintext highlighter-rouge">torch.transpose()</code></h4>

<p><strong>功能</strong>：交换张量的两个维度，常用于图像的预处理。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">dim0</span><span class="p">,</span>
    <span class="n">dim1</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">input</code>：要变换的张量。</li>
  <li><code class="language-plaintext highlighter-rouge">dim0</code>：要交换的维度。</li>
  <li><code class="language-plaintext highlighter-rouge">dim1</code>：要交换的维度。</li>
</ul>

<h4 id="torcht"><code class="language-plaintext highlighter-rouge">torch.t()</code></h4>

<p><strong>功能</strong>：2 维张量转置，对矩阵而言，等价于 <code class="language-plaintext highlighter-rouge">torch.transpose(input, 0, 1)</code>。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">t</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="torchsqueeze"><code class="language-plaintext highlighter-rouge">torch.squeeze()</code></h4>

<p><strong>功能</strong>：<strong>压缩</strong> 长度为 1 的维度（轴）。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">out</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">dim</code>：若为 <code class="language-plaintext highlighter-rouge">None</code>，移除所有长度为 1 的轴；若指定维度，当且仅当该轴长度为 1 时，可以被移除。</li>
</ul>

<h4 id="torchunsqueeze"><code class="language-plaintext highlighter-rouge">torch.unsqueeze()</code></h4>

<p><strong>功能</strong>：依据 <code class="language-plaintext highlighter-rouge">dim</code> <strong>扩展</strong> 维度。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">usqueeze</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">dim</span><span class="p">,</span>
    <span class="n">out</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">dim</code>：扩展的维度。</li>
</ul>

<h2 id="2-张量数学运算">2. 张量数学运算</h2>

<h3 id="21-加减乘除">2.1 加减乘除</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">add</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="n">addcdiv</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="n">addcmul</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="n">sub</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="n">div</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="n">mul</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="torchadd"><code class="language-plaintext highlighter-rouge">torch.add()</code></h4>

<p><strong>功能</strong>：逐元素计算 <code class="language-plaintext highlighter-rouge">input + alpha × other</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">add</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">other</span><span class="p">,</span>
    <span class="n">out</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>主要参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">input</code>：第一个张量。</li>
  <li><code class="language-plaintext highlighter-rouge">alpha</code>：乘项因子。</li>
  <li><code class="language-plaintext highlighter-rouge">other</code>：第二个张量。</li>
</ul>

<h4 id="torchaddcmul"><code class="language-plaintext highlighter-rouge">torch.addcmul()</code></h4>

<p><strong>功能</strong>：逐元素计算</p>

\[\texttt{out}_i = \texttt{input}_i + \texttt{value} \times \texttt{tensor1}_i \times \texttt{tensor2}_i\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">addcmul</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">tensor1</span><span class="p">,</span>
    <span class="n">tensor2</span><span class="p">,</span>
    <span class="n">out</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="torchaddcdiv"><code class="language-plaintext highlighter-rouge">torch.addcdiv()</code></h4>

<p><strong>功能</strong>：逐元素计算</p>

\[\texttt{out}_i = \texttt{input}_i + \texttt{value} \times \dfrac{\texttt{tensor1}_i}{\texttt{tensor2}_i}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">addcdiv</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">tensor1</span><span class="p">,</span>
    <span class="n">tensor2</span><span class="p">,</span>
    <span class="n">out</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="22-对数指数幂函数">2.2 对数、指数、幂函数</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">log10</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">log2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="nb">pow</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="23-三角函数">2.3 三角函数</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">acos</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cosh</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">asin</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">atan</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">atan2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="3-线性回归">3. 线性回归</h2>

<p><strong>线性回归</strong> 是分析一个变量与另外一（多）个变量之间关系的方法：</p>

\[y=wx+b\]

<p>其中，$y$ 是 <strong>因变量</strong>，$x$ 是 <strong>自变量</strong>，二者之间关系为 <strong>线性</strong>。</p>

<p><strong>分析</strong>：求解线性组合系数 $w$ 和 $b$。</p>

<p><strong>求解步骤</strong>：</p>

<ol>
  <li>
    <p>确定模型</p>

\[\text{Model:}\quad y=wx+b\]
  </li>
  <li>
    <p>选择损失函数</p>

\[\text{MSE:}\quad \dfrac{1}{n}\sum_{i=1}^{n}(y_i - \hat y_i)^2\]
  </li>
  <li>
    <p>求解梯度并更新 $w$ 和 $b$</p>

\[\begin{align}
w &amp;= w - \mathrm{LR} * w.\texttt{grad} \\[2ex]
b &amp;= b - \mathrm{LR} * w.\texttt{grad}
\end{align}\]

    <p>其中，$\mathrm{LR}$ 是 <strong>学习率 (learning rate)</strong>。</p>
  </li>
</ol>

<p><strong>代码示例</strong>：</p>

<center><video width="80%" controls="">
  <source src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-10-untitiled.mp4" type="video/mp4" />
</video></center>

<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># 学习率
</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># 创建训练数据
</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>  <span class="c1"># x data (tensor), shape=(20, 1)
</span><span class="n">y</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="mi">5</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># y data (tensor), shape=(20, 1)
</span>
<span class="c1"># 初始化线性回归参数
</span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>

    <span class="c1"># 向前传播
</span>    <span class="n">wx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">mul</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">wx</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

    <span class="c1"># 计算 MSE loss
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>

    <span class="c1"># 反向传播
</span>    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># 更新参数
</span>    <span class="n">b</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">lr</span> <span class="o">*</span> <span class="n">b</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>
    <span class="n">w</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">sub_</span><span class="p">(</span><span class="n">lr</span> <span class="o">*</span> <span class="n">w</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>

    <span class="c1"># 绘图
</span>    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

        <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="s">'r-'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="s">'Loss=%.4f'</span> <span class="o">%</span> <span class="n">loss</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s">'size'</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s">'color'</span><span class="p">:</span> <span class="s">'red'</span><span class="p">})</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Iteration: {}</span><span class="se">\n</span><span class="s">w: {} b: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">w</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">b</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">numpy</span><span class="p">()))</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="c1"># 当 loss &lt; 1 时，停止迭代更新
</span>        <span class="k">if</span> <span class="n">loss</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">break</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="4-总结">4. 总结</h2>

<p>本节课介绍了张量的基本操作，例如：张量的拼接、切分、索引和变换。同时，我们还学习了张量的数学运算，并基于所学习的知识，实现线性回归模型的训练，以加深知识点的认识。</p>

<p>下节内容：计算图与动态图机制</p>
:ET